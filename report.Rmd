---
title: 'StatComp Project 1:  3D printer materials estimation'
author: "Matthew Phillips (s2190456)"
output:
  html_document:
    number_sections: yes
  pdf_document:
    number_sections: yes
header-includes:
  - \newcommand{\bm}[1]{\boldsymbol{#1}}
  - \newcommand{\mat}[1]{\begin{bmatrix}#1\end{bmatrix}}
---
```{r setup, include = FALSE}
# Modify this setup code chunk to set options
# or add extra packages etc if needed.
# See the project instructions for more details
# on what code to show, and where/how.

# Set default code chunk options
knitr::opts_chunk$set(
  echo = TRUE,
  eval = TRUE
)

load("filament1.rda")
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(mvtnorm))
theme_set(theme_bw())

# To give the same random number sequence every time the document is knit:ed,
# making it easier to discuss the specific numbers in the text:
set.seed(12345L)
```

```{r code=readLines("code.R"), eval=TRUE, echo=FALSE}
# Do not change this code chunk
# Load function definitions
source("code.R")
```
# The data

To comment on the variability of the data we first observe for each material the weight predicted by the CAD software against its actual weight.

```{r Scatterplot1, echo=FALSE}
material_colors <- c("black", "chartreuse4", "magenta", "blue", "hotpink", "red")

reg <- lm(formula=Actual_Weight ~ CAD_Weight, data=filament1)
coeff <- coefficients(reg)
intercept <- coeff[1]
slope <- coeff[2]

ggplot(filament1, aes(x = CAD_Weight, y = Actual_Weight, color = Material)) +
  geom_point() +
  geom_smooth(formula=y~x, method = "lm", aes(x = CAD_Weight, y = Actual_Weight), se=FALSE, color="black", linewidth = 0.5) +
  scale_color_manual(values = material_colors) +
  labs(title = "CAD Weight vs. Actual Weight",
       x = "CAD Weight (grams)", 
       y = "Actual Weight (grams)") +
  theme_minimal()
```

```{r Scatterplot2, echo=FALSE}
ggplot(filament1, aes(x = CAD_Weight, y = Actual_Weight, color = Material)) +
  geom_point() +
  facet_wrap(filament1$Material ~ .) +
  scale_color_manual(values = material_colors) +
  labs(title = "CAD Weight vs. Actual Weight for Different Materials",
       x = "CAD Weight (grams)", 
       y = "Actual Weight (grams)" ) +
  theme_minimal()
```

We can see that for the neon pink material we only have a limited number of observations and thus it will be harder to make any reasonable judgments based solely on this data set for this material. The observations for the magenta and neon blue materials are also widely spaced leaving large gaps and making it harder to accurately predict the values in those regions. However, we can see that on the whole the points lie on a line with formula $y = 1.0798775x - 0.1097023$ indicating that there is a roughly one-to-one linear relationship between the predicted weights and actual weights. There is also very low variability in the data as it is spread very tightly around this line.

Now we look at the box plots of the CAD-predicted weight for each material to examine variability across different materials. 

```{r Boxplot, echo=FALSE}
alpha_fill <- 0.4

ggplot(filament1) +
  geom_boxplot(aes(x = Material, y = CAD_Weight, color = Material, fill = Material), ) +
  scale_color_manual(values = material_colors) +  # Set custom colors
  scale_fill_manual(values = alpha(material_colors, alpha_fill)) +
  labs(title = "CAD Weight Distribution by Material",
       x = "Material",
       y = "CAD Weight (grams)") +
  theme_minimal()
```

As before, we see the neon pink material has values only in a very small range making it less useful. The black and green materials have similar interquartile ranges (IQR) but the whiskers of the green material are longer indicating more variance. We see the red material has the largest spread but from the previous graph it also has the most data points. The blue material has a larger IQR but very low median indicating a large skew whereas the other materials exhibit fairly low skew. The red material has the largest IQR and median centred in it indicating a fairly even spread across the range. 

Magenta has a cluster in the middle with several outliers indicating a large spread of the data and again making it hard for the data to be used reliably as the presence of outliers affects the predictability of the variability of the data. 

We also see a significant difference in the median values for each material with red having the highest and blue and black being the two lowest implying there may be a variation in the average CAD-predicted weights of each material. This is potentially caused by each material being used to make different types of parts with different weights. 

# Classical estimation 

Given the two models 

$$
\text{Model A}: y_i \sim \text{Normal}[\beta_1 + \beta_2x_i, \exp(\beta_3 + \beta_4x_i)] \\
\text{Model B}: y_i \sim \text{Normal}[\beta_1 + \beta_2x_i, \exp(\beta_3) + \exp(\beta_4)x_i^2]
$$

where $x_i$ are the CAD-predicted observations and $y_i$ are the actual weights for observation $i$ , we start by finding the negated log-likelihood of each model using a function `neg_log_like()` which, for each $x_i$ and given $\beta_i$ parameters calculates the relevant $\mu$ and $\sigma$ for each model and then, for each $y_i$ computes the log of the corresponding Normal distribution at that value and then sums each of these and negates it.

The best set of parameters are then found using a function `filament1_estimate()` which first minimises the negated log_likelihood function and then finds approximate 90% confidence intervals using the approximation method for large $n$, i.e., by solving the hessian matrix of the solution found and using that as an approximation of the standard error.

```{r Parameter Estimation, echo=FALSE, include=FALSE}
fit_A <- filament1_estimate(filament1, 'A')
fit_B <- filament1_estimate(filament1, 'B')
```

```{r Confidence Intervals , echo=FALSE}
ciA <- CI(fit_A)
ciB <- CI(fit_B)

colnames(ciA) <- c("Lower Bound", "Upper Bound")
rownames(ciA) <- c("β1", "β2", "β3", "β4")
colnames(ciB) <- c("Lower Bound", "Upper Bound")
rownames(ciB) <- c("β1", "β2", "β3", "β4")

knitr::kable(ciA, caption = "Table displaying 90% confidence intervals for parameters of Model A")

knitr::kable(ciB, caption = "Table displaying 90% confidence intervals for parameters of Model B")
```

Comparing the values found, we see that the parameters involved in the mean of the Normal distribution for each model, i.e., $\beta_1$ and $\beta_2$ remain fairly similar, especially $\beta_2$. This is to be expected as the mean of both models is the same. For $\beta_3$ and $\beta_4$, however, the values are very different and the widths of the confidence intervals are much larger as well, especially $\beta_3$. 

Generally, Model A shows more precision in estimating the parameters as is demonstrated by the smaller confidence intervals for $\beta_1$, $\beta_3$ and $\beta_4$. Model B shows substantial uncertainty when computing $\beta_3$ as seen by the large interval. The confidence intervals for $\beta_1$ in Model A and $\beta_3$ in Model B include 0, however, indicating that they do not have a significant effect on the response variable. 

# Bayesian estimation

We now consider a different model, again with $x_i$ as the CAD weights and $y_i$ the actual weights for observation $i$, described by

$$
y_i \sim \text{Normal}[\beta_1 + \beta_2x_i, \beta_3 + \beta_4x_i^2]
$$
with the parametrisation $\boldsymbol{\theta} = [\theta_1, \theta_2, \theta_3, \theta_4] = [\beta_1, \beta_2, \log(\beta_3), \log(\beta_4)]$ where

$$
\theta_1 \sim \text{Normal}(0, \gamma_1), \\
\theta_2 \sim \text{Normal}(1, \gamma_2), \\
\theta_3 \sim \text{LogExp}(\gamma_3), \\
\theta_4 \sim \text{LogExp}(\gamma_4)
$$
and the $\boldsymbol{\gamma} = [\gamma_1, \gamma_2, \gamma_3, \gamma_4]$ values are positive paramaters.

## Prior Density
To find the logarithm of the joint prior density, $p(\boldsymbol{\theta})$, we first compute the logarithms of the priors of each $\theta_i$ and then sum them for the joint prior density.

## Observation Likelihood
To find the log-likelihood of this model $p(\mathbf{y}|\boldsymbol{\theta})$ for the above model we compute each $\beta_i$ using the given parametrisation and then compute the mean and standard deviation of the Normal distribution used in the model before computing the log-likelihood of each observation before summing them for the total log-likelihood.

## Posterior Density
To find the logarithm of the posterior density $p(\boldsymbol{\theta}|\mathbf{y})$ up to some normalisation constant we simply sum the previously computed prior density and observation log-likelihood for the data.

## Posterior Mode
To find the mode of the log-posterior-density we optimise the log-posterior-density function to find the point estimate with the highest value. We also compute the Hessian matrix and inverse of the negated Hessian matrix at this point to provide information that will be used to approximate the standard error for the density in later calculations.

## Gaussian Approximation
The following code computes the values of $\boldsymbol{\mu}$ and $\mathbf{S}$ in order to obtain a multivariate Normal approximation for the log-posterior-distribution $p(\boldsymbol{\theta}|\mathbf{y}) \sim \text{Normal}(\boldsymbol{\mu}, \mathbf{S})$. It uses parameters $\boldsymbol{\gamma} = [1, 1, 1, 1]$ and starting values $\boldsymbol{\theta} = [0, 0, 0, 0]$ and uses the `posterior_mode()` function described above to return the mode, $\boldsymbol{\mu}$, and the inverse of the negated Hessian matrix, or covariance matrix, at the mode, $\mathbf{S}$.

```{r Gaussian Approx}
gamma_values <- rep(1, 4)
theta_init <- rep(0, 4) 
x_values <- filament1$CAD_Weight
y_values <- filament1$Actual_Weight

p_mode <- posterior_mode(theta_init, x_values, y_values, gamma_values)

mode <- p_mode$mode
hessian <- p_mode$hessian
cov_mat <- p_mode$S

mode

cov_mat
```
As we can see from the above code the multivariate Normal approximation is given by $\text{Normal}(\boldsymbol{\mu}, \mathbf{S})$ where  


$$
\boldsymbol{\mu} = [-0.1008234, 1.0800211, -2.9834581, -6.7584316]
$$
and
$$
\mathbf{S} =
\begin{bmatrix} 
0.0082951754 & -3.431287e-04 & 0.03033564 & -0.0042956177 \\ 
-0.0003431287 & 2.995519e-05 & -0.00149660 & 0.0002120789 \\ 
0.0303356430 & -1.496600e-03 & 1.06644653 & -0.1239715048 \\
-0.0042956177 & 2.120789e-04 & -0.12397150 & 0.0454331418
\end{bmatrix}
$$

## Importance Sampling Function

The `do_importance()` function implements the Monte-Carlo method of importance sampling by drawing samples from a multivariate Normal distribution centred at the mode of the log-posterior-density to approximate the integral and allow for the calculation of normalised log-weights.

## Importance Sampling

The computed importance sample of size N = 10,000 is visualised using the `stat_ewcdf()` and `stat_ecdf()` functions to produce a plot of the weighted and unweighted cumulative density functions.


```{r Importance Sample, echo=TRUE}
N <- 10000
mu <- mode
sd <- cov_mat

importance_sample <- do_importance(N, mu, sd, x_values, y_values, gamma_values)
```

```{r CDFs, echo=FALSE}
# Reshape data for plotting
importance_sample_long <- importance_sample %>%
  pivot_longer(cols = starts_with("β"), names_to = "Parameter", values_to = "Value")

# Plot
ggplot(importance_sample_long, aes(x = Value, color = "red")) +
  stat_ewcdf(aes(weights = exp(log_weights_normalised))) +
  stat_ecdf(geom = "step", aes(color = "blue")) +
  facet_wrap(~ Parameter, scales = "free") +
  labs(title = "Empirical Weighted and Unweighted CDFs",
       x = "Parameter Values",
       y = "Cumulative Probability") +
  scale_color_manual(values = c("red" = "red", "blue" = "blue"), labels = c("red" = "Weighted CDF", "blue" = "Unweighted CDF")) +
  theme_minimal()
```

The following code generates 90% credible intervals for each $\beta_i$.
```{r Credible Intervals, echo=TRUE}
credible_intervals <- importance_sample_long %>%
  group_by(Parameter) %>%
  summarise(credible_interval = list(make_CI(Value, exp(log_weights_normalised), 0.90))) %>%
  unnest(cols = credible_interval)
```

```{r Credible Intervals Table, echo=FALSE}
knitr::kable(credible_intervals, caption = "Credible intervals for β parameters")
```
 
We can see the credible intervals for the parameter values are all relatively narrow indicating a good degree of precision and that the sampling method has captured the characteristics of the posterior distribution, however the interval for $\beta_1$ includes 0 which leads to the conclusion that it may not have a significant impact on the model. 

The $\beta_1$ parameter represents the intercept of the model. Since its credible interval contains 0 it is implied that it is not statistically different from 0 which agrees with what we observe in the first graphs as the observed linear relation appears to go through the origin. This suggests the model is only dependent on the linear terms of $x_i$.  $\beta_2$ being close to 1 makes sense similarly as it is the coefficient of the linear term used to estimate the mean of the Normal distribution and in the graphs the line appears to have a slope of 1.

The fact that both $\beta_3$ and $\beta_4$ are close to 0 would indicate that there is very little variability in the model as they are the parameters used to estimate the variance of the Normal distribution which follows what we see in the first graphs of CAD-Weight against Actual Weight where the values lie very close to the line. Looking at the weighted CDF for $\beta_3$ we see that there is a very steep jump closely after 0 indicating that almost all of the observed parameter values are very small with very few values larger than that. This implies that the smaller the predictor variable the larger the impact of the $\beta_3$ parameter on the response. However, them not being exactly 0 also fits with our observation before as, since $\beta_4$ is multiplied by the quadratic term, $x_i^2$, the variance of the data becomes greater as the CAD-Weight, $x_i$, increases, mirroring what we see in the graph.

Overall, this leads us to the conclusion that the statistical techniques used in this investigation have been successful and the model used is a good fit for the given data and could be used to predict actual weights for the 3D printer going forward.

```{r Log-weights, echo=FALSE}
ggplot(importance_sample_long, aes(x = Value, y = log_weights_normalised)) +
  geom_point(size=0.01, alpha=0.4) +
  facet_wrap(~ Parameter, scales = "free") + 
  labs(title = "Log-Weights against Parameter Value",
       x = "Parameter Values",
       y = "Normalised Log-Weight") +
  theme_minimal()
```

We can see that applying weights to the empirical CDFs has a significant impact on their graphs, pulling them towards values of more importance to the model. We can also observe the most important values by seeing where the largest jumps in the weighted CDFs are and since these are all within the credible intervals we can conclude that the modeling and sampling techniques used have, on the whole, been successful. Looking at the credible intervals we see that generally the weighted CDFs are also a good approximation for the data as the 90% credible interval ranges from the 5th to 95th percentiles of the CDF.

The log-weights for the $\beta_1$ and $\beta_2$ parameters appear to follow similar distributions, fairly evenly spread and symmetrical about the credible interval, as we would expect of parameters that have been modeled by Normal distributions. $\beta_3$ has most of its log-weights skewed heavily towards the bottom of the range of parameter values as we would expect from an exponentially distributed variable. $\beta_4$, also has its log weights skewed towards the lower end of the range but not as heavily as $\beta_4$ which is what we would expect of an exponentially distributed variable but could indicate the potential for it to be modeled by something else as it is not as explicit as the spread of $\beta_3$.

# Code appendix

```{r code=readLines("code.R"), eval=FALSE, echo=TRUE}
# Do not change this code chunk
```
























